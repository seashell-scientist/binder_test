{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('Arrest_Data_from_2010_to_Present.csv') # read in the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete columns not relevant to analysis\n",
    "df.drop(['Report ID','Area ID','Charge Group Code','Location'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to cleanup the time field...it is stored like 645 instead of 06:45\n",
    "df_cleansed = df\n",
    "\n",
    "#convert float to string\n",
    "df_cleansed['Time'] = df_cleansed['Time'].astype(str) \n",
    "\n",
    "#get rid of decimals\n",
    "df_cleansed['Time'] = df_cleansed['Time'].str.split(\".\", expand=True)[0] \n",
    "\n",
    "#convert missing to 0000\n",
    "df_cleansed['Time'] = df_cleansed['Time'].replace(to_replace=\"nan\",value=\"0000\") \n",
    "\n",
    "#treat 0 as missing and convert to 0000\n",
    "df_cleansed['Time'] = df_cleansed['Time'].replace(to_replace=\"0\",value=\"0000\") \n",
    "\n",
    "#2400 is not a valid time, converting to 0001 so it isn't the same as missing\n",
    "df_cleansed['Time'] = df_cleansed['Time'].replace(to_replace=\"2400\",value=\"0001\") \n",
    "\n",
    "#split the time string to get the appropriate digits that correspond to hours and minutes\n",
    "df_cleansed['Hour'] = np.where(df_cleansed['Time'].str.len() == 4,df_cleansed['Time'].str[-4:2],np.where(df_cleansed['Time'].str.len() == 3,df_cleansed['Time'].str[-3:1],\"00\"))\n",
    "df_cleansed['Minute'] = df_cleansed['Time'].str[-2:4]\n",
    "\n",
    "#put hour and minute back together in time format\n",
    "df_cleansed['NewTime'] = pd.to_datetime(df_cleansed['Hour'] + ':' + df_cleansed['Minute'] + ':00',format='%H:%M:%S').dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to clean up cross street field\n",
    "\n",
    "#remove duplicate whitespaces\n",
    "df_cleansed['Cross Street'] = df_cleansed['Cross Street'].replace('\\s+',' ',regex=True)\n",
    "df_cleansed['Address'] = df_cleansed['Address'].replace('\\s+',' ',regex=True)\n",
    "\n",
    "#if all digits are numeric, nullify\n",
    "df_cleansed['Address New'] = np.where(df_cleansed[\"Address\"].str.isdigit() == True,np.nan, df_cleansed[\"Address\"])\n",
    "df_cleansed['Cross Street New'] = np.where(df_cleansed[\"Cross Street\"].str.isdigit() == True,np.nan, df_cleansed[\"Cross Street\"])\n",
    "\n",
    "df_cleansed['Address_first_word'] = df_cleansed['Address'].str.split(n=1).str[0]\n",
    "df_cleansed['Street'] = np.where(df_cleansed['Address_first_word'].str.isdigit() == True,df_cleansed['Address'].str.split(n=1).str[1],df_cleansed['Address'])\n",
    "\n",
    "df_cleansed['Cross_street_first_word'] = df_cleansed['Cross Street'].str.split(n=1).str[0]\n",
    "df_cleansed['CrossStreet'] = np.where(df_cleansed['Cross_street_first_word'].str.isdigit() == True,df_cleansed['Cross Street'].str.split(n=1).str[1],df_cleansed['Cross Street'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete columns not relevant to analysis\n",
    "df_cleansed.drop(['Time','Hour','Minute','Address','Cross Street','Address New','Cross Street New','Address_first_word','Cross_street_first_word'],axis=1,inplace=True)\n",
    "\n",
    "#add year column\n",
    "df_cleansed['Date'] = pd.to_datetime(df_cleansed['Arrest Date'])\n",
    "df_cleansed['Year'] = df_cleansed['Date'].dt.year\n",
    "df_cleansed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test = df_cleansed[df_cleansed['Address_numeric'] == True]\n",
    "#print (df_test)\n",
    "#df_test = df_cleansed.groupby(by='Cross Street')\n",
    "#print (df_test['Cross Street'].count())\n",
    "#df_test = df_cleansed.groupby(by='Reporting District')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_counts = df_cleansed['Reporting District'].value_counts().reset_index().rename(columns={'index': 'Key'})\n",
    "district_counts.columns = ['Key', 'District Counts']\n",
    "#district_counts\n",
    "\n",
    "male = df_cleansed[df_cleansed['Sex Code'] == 'M']\n",
    "male_counts = male['Reporting District'].value_counts().reset_index().rename(columns={'index': 'key'})\n",
    "male_counts.columns = ['Key','Male_Counts']\n",
    "#male_counts\n",
    "\n",
    "female = df_cleansed[df_cleansed['Sex Code'] == 'F']\n",
    "female_counts = female['Reporting District'].value_counts().reset_index().rename(columns={'index': 'key'})\n",
    "female_counts.columns = ['Key','Female_Counts']\n",
    "#female_counts\n",
    "\n",
    "year_counts = df_cleansed.groupby(['Reporting District','Year']).size().reset_index()\n",
    "year_counts.columns = ['Key','Year','Year_Dist_Counts']\n",
    "#year_counts\n",
    "\n",
    "merged1 = district_counts.merge(male_counts, left_on='Key', right_on='Key')\n",
    "merged2 = merged1.merge(female_counts,left_on='Key', right_on='Key')\n",
    "merged2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#year_counts.to_csv(r'counts.csv')\n",
    "df_cleansed.to_csv(r'Cleansed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://www.acgeospatial.co.uk/geopandas-shapefiles-jupyter/\n",
    "#http://geohub.lacity.org/datasets/4398360b1a0242b78904f46b3786ae73_0/data\n",
    "\n",
    "import geopandas as gpd\n",
    "gdf = gpd.read_file('LAPD_Reporting_Districts.shp')\n",
    "#print (gdf)\n",
    "\n",
    "#merge polygon dataframe with counts by reporting district\n",
    "gdf1 = gdf.merge(merged2, left_on='REPDIST', right_on='Key')\n",
    "gdf1['Counts by Area'] = gdf1['District Counts']/gdf1['AREA']\n",
    "gdf2 = gdf1.merge(year_counts, left_on='REPDIST',right_on='Key')\n",
    "print(gdf2.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "#gdf3.head()\n",
    "gdf1.plot(column='District Counts', cmap=None, figsize=(10, 10),  legend=True)\n",
    "plt.title('Arrests by District')\n",
    "gdf1.plot(column='Counts by Area', cmap=None, figsize=(10, 10),  legend=True)\n",
    "plt.title('Arrests by Distict / Area')\n",
    "gdf1.plot(column='Male_Counts', cmap=None, figsize=(10, 10),  legend=True)\n",
    "plt.title('Male Arrests by Distict')\n",
    "gdf1.plot(column='Female_Counts', cmap=None, figsize=(10, 10),  legend=True)\n",
    "plt.title('Female Arrests by Distict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/a-complete-guide-to-an-interactive-geographical-map-using-python-f4c5197e23e0\n",
    "#https://github.com/CrazyDaffodils/Interactive-Choropleth-Map-Using-Python\n",
    "\n",
    "import json\n",
    "\n",
    "#Read data to json\n",
    "merged_json = json.loads(gdf2.to_json())\n",
    "\n",
    "#Convert to str like object\n",
    "json_data = json.dumps(merged_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook, show, output_file\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import GeoJSONDataSource, LinearColorMapper, ColorBar\n",
    "from bokeh.palettes import brewer\n",
    "\n",
    "#Input GeoJSON source that contains features for plotting.\n",
    "geosource = GeoJSONDataSource(geojson = json_data)\n",
    "\n",
    "#Define a sequential multi-hue color palette.\n",
    "palette = brewer['YlGnBu'][9]\n",
    "\n",
    "#Reverse color order so that dark blue is highest obesity.\n",
    "#palette = palette[::-1]\n",
    "\n",
    "#Instantiate LinearColorMapper that linearly maps numbers in a range, into a sequence of colors.\n",
    "color_mapper = LinearColorMapper(palette = palette, low = 0, high = 2500)\n",
    "\n",
    "#Define custom tick labels for color bar.\n",
    "#tick_labels = {'0': '0%', '5': '5%', '10':'10%', '15':'15%', '20':'20%', '25':'25%', '30':'30%','35':'35%', '40': '>40%'}\n",
    "\n",
    "#Create color bar. \n",
    "color_bar = ColorBar(color_mapper=color_mapper, label_standoff=8,width = 500, height = 20,\n",
    "#border_line_color=None,location = (0,0), orientation = 'horizontal', major_label_overrides = tick_labels)\n",
    "border_line_color=None,location = (0,0), orientation = 'horizontal')\n",
    "\n",
    "#Create figure object.\n",
    "p = figure(title = 'Los Angeles Arrests by Reporting District', plot_height = 950 , plot_width = 600, toolbar_location = None)\n",
    "p.xgrid.grid_line_color = None\n",
    "p.ygrid.grid_line_color = None\n",
    "\n",
    "#Add patch renderer to figure. \n",
    "p.patches('xs','ys', source = geosource,fill_color = {'field' :'District Counts', 'transform' : color_mapper},\n",
    "          line_color = 'black', line_width = 0.25, fill_alpha = 1)\n",
    "\n",
    "#Specify figure layout.\n",
    "p.add_layout(color_bar, 'below')\n",
    "\n",
    "#Display figure inline in Jupyter Notebook.\n",
    "output_notebook()\n",
    "\n",
    "#Display figure.\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import curdoc, output_notebook\n",
    "from bokeh.models import Slider, HoverTool\n",
    "from bokeh.layouts import widgetbox, row, column\n",
    "\n",
    "#Define function that returns json_data for year selected by user.\n",
    "    \n",
    "def json_data(selectedYear):\n",
    "    yr = selectedYear\n",
    "    df_yr = gdf2[gdf2['Year'] == yr]\n",
    "    #merged = gdf.merge(df_yr, left_on = 'country_code', right_on = 'code', how = 'left')\n",
    "    #merged.fillna('No data', inplace = True)\n",
    "    merged_json = json.loads(df_yr.to_json())\n",
    "    json_data = json.dumps(merged_json)\n",
    "    return json_data\n",
    "\n",
    "#Input GeoJSON source that contains features for plotting.\n",
    "geosource = GeoJSONDataSource(geojson = json_data(2010))\n",
    "\n",
    "#Define a sequential multi-hue color palette.\n",
    "palette = brewer['YlGnBu'][9]\n",
    "\n",
    "#Reverse color order so that dark blue is highest obesity.\n",
    "#palette = palette[::-1]\n",
    "\n",
    "#Instantiate LinearColorMapper that linearly maps numbers in a range, into a sequence of colors. Input nan_color.\n",
    "color_mapper = LinearColorMapper(palette = palette, low = 0, high = 2500)\n",
    "\n",
    "#Define custom tick labels for color bar.\n",
    "#tick_labels = {'0': '0%', '5': '5%', '10':'10%', '15':'15%', '20':'20%', '25':'25%', '30':'30%','35':'35%', '40': '>40%'}\n",
    "\n",
    "#Add hover tool\n",
    "hover = HoverTool(tooltips = [ ('Reporting District','@REPDIST'),('Arrests', '@Year_Dist_Counts')])\n",
    "\n",
    "\n",
    "#Create color bar. \n",
    "color_bar = ColorBar(color_mapper=color_mapper, label_standoff=8,width = 500, height = 20,\n",
    "                     border_line_color=None,location = (0,0), orientation = 'horizontal')\n",
    "\n",
    "\n",
    "#Create figure object.\n",
    "p = figure(title = 'Los Angeles Arrests by Reporting District', plot_height = 850 , plot_width = 600, toolbar_location = None, tools = [hover])\n",
    "p.xgrid.grid_line_color = None\n",
    "p.ygrid.grid_line_color = None\n",
    "\n",
    "#Add patch renderer to figure. \n",
    "p.patches('xs','ys', source = geosource,fill_color = {'field' :'Year_Dist_Counts', 'transform' : color_mapper},\n",
    "          line_color = 'black', line_width = 0.25, fill_alpha = 1)\n",
    "\n",
    "\n",
    "p.add_layout(color_bar, 'below')\n",
    "\n",
    "# Define the callback function: update_plot\n",
    "def update_plot(attr, old, new):\n",
    "    yr = slider.value\n",
    "    new_data = json_data(yr)\n",
    "    geosource.geojson = new_data\n",
    "    p.title.text = 'Arrest Counts' %yr\n",
    "    \n",
    "# Make a slider object: slider \n",
    "slider = Slider(title = 'Year',start = 2010, end = 2019, step = 1, value = 2010)\n",
    "slider.on_change('value', update_plot)\n",
    "\n",
    "# Make a column layout of widgetbox(slider) and plot, and add it to the current document\n",
    "layout = column(p,widgetbox(slider))\n",
    "curdoc().add_root(layout)\n",
    "\n",
    "#Display plot inline in Jupyter notebook\n",
    "output_notebook()\n",
    "\n",
    "#Display plot\n",
    "show(layout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
